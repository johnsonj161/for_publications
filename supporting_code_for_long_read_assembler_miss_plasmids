# Supporting code for the "Long read genome assemblers struggle with small plasmids".
# Prepared by Jared Johnson on February 13, 2023

##---READ PROCESSING---###
# Illumina short reads
## trimming and quality filtering with Fastp
fastp \
    -i R1.fastq.g \
    -I R2.fastq.gz \
    -o R1-trimmed.fastq.gz \
    -O R2-trimmed.fastq.gz

# ONT long reads
## high accuracy basecalling with Guppy
guppy_basecaller \
    --compress_fastq \
    -i path/to/fast5 \
    -s path/to/output \
    --num_callers 4 \
    -c dna_r9.4.1_450bps_hac.cfg \
    --min_qscore 8 \
    --trim_adapters \
    -x 'cuda:0'

## combine all high accuracy files into one
cat *.fastq.gz > combined_ont.fastq.gz

## split reads into subsets with Trycyler
trycycler subsample \
    --threads 10 \
    --reads combined_ont.fastq.gz \
    --out_dir path/to/output \
    --count 3

###---INDIVIDUAL DRAFT ASSEMBLIES---###
# Flye
## flye-raw
flye \
    --nano-raw ont_subset.fastq \
    --out-dir path/to/output \
    --threads 10

## flye-hq
flye \
    --nano-hq ont_subset.fastq \
    --out-dir path/to/output \
    --threads 10

## flye-meta
flye \
    --meta \
    --nano-hq ont_subset.fastq \
    --out-dir path/to/output \
    --threads 10

# Miniasm
minimap2 -t 10 -x ava-ont ont_subset.fastq ont_subset.fastq > ont_subset.paf
miniasm -f ont_subset.fastq ont_subset.paf > ont_subset.gfa
minipolish -t 10 ont_subset.fastq ont_subset.paf | awk '$1 ~/S/ {print ">"$2"\n"$3}' > ont_subset-miniasm.fasta

# Raven
raven -t 10 ont_subset.fastq > ont_subset-raven.fasta

# Unicycler
unicycler -1 R1-trimmed.fastq.gz -2 R2-trimmed.fastq.gz -l ont_subset.fastq -t 10 -o path/to/output

###---COMPLETED HYBRID ASSEMBLIES---#
# cluster contigs with Trycycler
trycycler cluster \
    --assemblies *.fasta \
    --reads combined_ont.fastq.gz \
    --out_dir path/to/output \
    --threads 10

# generate cluster metrics
## identifying top BLAST hits of a representative contigs
blastn \
    -query contig.fasta \
    -db nt \
    -remote \
    -perc_identity 95 \
    -qcov_hsp_perc 95 \
    -out blastn_result.txt

## dotplots
trycyler dotplot \
    --cluster_dir path/to/cluster_dir

## plot contig tree (performed in R)
tree <- ape::read.tree(contigs.newick)
jpeg(contig_tree.jpeg, res = 300, height = 5000, width = 5000)
par(mar=c(0.1, 0.1, 0.1, 0.1))
plot(tree)
dev.off()"

# generate hybrid assembly
## reconcile contigs
trycycler reconcile \
    --reads combined_ont.fastq.gz \
    --cluster_dir path/to/cluster_dir

## multiple sequence alignment
trycycler msa \
    --cluster_dir path/to/cluster_dir

## partition long reads
trycycler partition \
    --reads combined_ont.fastq.gz \
    --cluster_dirs path/to/cluster_dirs*

## create consensus
trycycler consensus \
    --cluster_dir path/to/cluster_dir

# polish hyrbid assembly
## polish with long reads using Medaka (x3)
medaka_consensus \
    -i combined_ont.fastq.gz \
    -d rough_assembly.fasta \
    -o long-polished-assembly-${i}.fasta \
    -m r941_min_hac_g507 \
    -t $threads \
    -x -f
## polish with short reads using Polypolish (x3)
bwa index long-polished-assembly-3.fasta
bwa mem -t 10 -a long-polished-assembly-3.fasta R1-trimmed.fastq.gz > fwd_read_alignments.sam
bwa mem -t 10 -a long-polished-assembly-3.fasta R2-trimmed.fastq.gz > rev_read_alignments.sam

polypolish_insert_filter.py \
    --in1 fwd_read_alignments.sam  \
    --in2 rev_read_alignments.sam \
    --out1 fwd_read_alignments_filtered.sam \
    --out2 rev_read_alignments_filtered.sam

polypolish long-polished-assembly-3.fasta fwd_read_alignments_filtered.sam rev_read_alignments_filtered.sam > short-polished-${i}.fasta

###---PLASMID RECOVERY ANALYSIS---###
# general read statistics
## map Illumina short reads
bwa index completed_assembly.fasta
bwa mem -t 40 completed_assembly.fasta R1-trimmed.fastq.gz R2-trimmed.fastq.gz \
    | samtools view -b - \
    | samtools sort - > short.bam

## map ONT long reads
minimap2 \
    -t 20 \
    -ax map-ont \
    completed_assembly.fasta ont_subset.fastq \
    --secondary=no \
    | samtools sort - > $isolate/stats/long.bam

## calculate read stats for each contig
samtools index short.bam
samtools view -b [long|short].bam "contig_name" > contig.bam
samtools stats contig.bam > contig.stats
samtools depth contig.bam > contig.depth
total_depth=$(awk 'BEGIN{FS="\t"; sum=1} {sum+=$3} END{print sum}' contig.depth)
num_bases=$(cat contig.depth | wc -l)
cov=$(echo "$total_depth / $num_bases" | bc)
cat contig.stats \
    | grep "SN" \
    | grep -v "#" \
    | sed 's/^SN.*.:\t//g' \
    | tr "\n" "\t" \
    | awk -v a="$isolate" -v b="$contig" -v c="short" -v d="$cov" -v OFS="\t" '{print a, b, c, d, $0}' > read-stats.txt
cat contig.stats \
      | grep "unmapped" \
      | sed 's/SN.*.:\t//g' \
      | awk -v a="$isolate" -v b="$assembly" '{print a, b, $1}' > unmapped.txt

# plasmid recovery
## map draft assemblies to the completed assembly
minimap2 \
    -x asm5 \
    draft_assembly.fasta \
    completed_assembly.fasta \
    --paf-no-hit \
    | awk -v OFS="\t" -v a=$isolate -v b=$assembly '{print a, b, $0}' > draft_alignment.txt

## Classify plasmids as present or absent (performed in R)
df <- read_tsv("draft_alignment.txt", col_names = F)
per_assembly <- function(assembly, df){
  # subset paf file by the assembly
  df.assembly <- df[df$X2 == assembly,]
  # iterate over reference contigs
  per_ref_contig <- function(contig, df){
    # subset paf file by reference contig
    df.ref <- df[df$X3 == contig,]
    # iterate over draft contigs
    per_draft_contig <- function(contig, df){
      # subset by draft contig
      df.draft <- df[df$X8 == contig,]
      # define constants
      isolate <- unique(df.draft$X1)
      assembly <- unique(df.draft$X2)
      draft_size <- unique(df.draft$X9)
      draft_align <- sum(df.draft$X13)
      ref_contig <- unique(df.draft$X3)
      ref_size <- unique(df.draft$X4)
      # classify as chromosome or plasmid
      class <- "plasmid"
      if(draft_size > 1000000){
        class <- "chromosome"
      }
      result <- data.frame(isolate=isolate,
                           assembly=assembly,
                           ref_contig=ref_contig,
                           ref_size=ref_size,
                           draft_contig=contig,
                           draft_size=draft_size,
                           draft_align=draft_align,
                           class=class,
                           filter="pass")
      return(result)
    }
    # combine output
    df.called <- do.call(rbind, lapply(unique(df.ref$X8), FUN=per_draft_contig, df=df.ref))
    # remove alignments that are less than 90% of the reference contig length
    df.called.filtered <- df.called[df.called$draft_align > 0.90*df.called$ref_size | df.called$draft_size == 0,]
    # check if filtering resulted in an empty dataframe
    if(dim(df.called.filtered)[1] == 0){
      df.called.filtered <- data.frame(isolate=unique(df.called$isolate),
                         assembly=unique(df.called$assembly),
                         ref_contig=unique(df.called$ref_contig),
                         ref_size=unique(df.called$ref_size),
                         draft_contig=paste(df.called$draft_contig, collapse = ", "),
                         draft_size=paste(df.called$draft_size, collapse = ", "),
                         draft_align=paste(df.called$draft_align, collapse = ", "),
                         draft_align_total=sum(df.called$draft_align),
                         class = paste(df.called$class, collapse = ", "),
                         filter="fail - all alignments too short"
                         )
      # check for fragmented contigs - sum of multiple short draft contigs aligned to the reference equal at least 90% of the reference length
      if(df.called.filtered$draft_align_total > 0.90*df.called$ref_size){
        df.called.filtered$filter="pass - fragmented"
      }
    }
    # collapse multiple rows
    result <- data.frame(isolate=unique(df.called.filtered$isolate),
                         assembly=unique(df.called.filtered$assembly),
                         ref_contig=unique(df.called.filtered$ref_contig),
                         ref_size=unique(df.called.filtered$ref_size),
                         draft_contig=paste(df.called.filtered$draft_contig, collapse = ", "),
                         draft_size=paste(df.called.filtered$draft_size, collapse = ", "),
                         draft_align=paste(df.called.filtered$draft_align, collapse = ", "),
                         draft_align_total=sum(df.called$draft_align),
                         class = paste(df.called.filtered$class, collapse = ", "),
                         filter=unique(df.called.filtered$filter)
                         )
    return(result)
  }
  # combine output and return result
  result <- do.call(rbind, lapply(unique(df.assembly$X3), FUN=per_ref_contig, df=df.assembly))
  return(result)
}

df.pres_abs <- do.call(rbind, lapply(unique(all.paf[all.paf$X4 < 1000000,]$X2), FUN=per_assembly, df=all.paf[all.paf$X4 < 1000000,]))
